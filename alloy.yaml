---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: alloy
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: alloy
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - nodes/metrics
  - services
  - endpoints
  - pods
  - pods/log
  - events
  - configmaps
  - secrets
  - namespaces
  verbs: ["get", "list", "watch"]
- apiGroups: ["apps"]
  resources:
  - deployments
  - daemonsets
  - replicasets
  - statefulsets
  verbs: ["get", "list", "watch"]
- nonResourceURLs: ["/metrics", "/metrics/cadvisor"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: alloy
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: alloy
subjects:
- kind: ServiceAccount
  name: alloy
  namespace: default
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: alloy-config
data:
  config.alloy: |
    logging {
      level  = "info"
      format = "logfmt"
    }

    discovery.kubernetes "nodes" {
      role = "node"
    }

    discovery.kubernetes "pods" {
      role = "pod"
    }

    prometheus.scrape "kubelet" {
      targets = discovery.kubernetes.nodes.targets
      forward_to = [prometheus.remote_write.default.receiver]
      
      scrape_interval = "30s"
      metrics_path = "/metrics"
      scheme = "https"
      bearer_token_file = "/var/run/secrets/kubernetes.io/serviceaccount/token"
      tls_config {
        ca_file = "/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"
        insecure_skip_verify = true
      }
    }

    prometheus.scrape "cadvisor" {
      targets = discovery.kubernetes.nodes.targets
      forward_to = [prometheus.remote_write.default.receiver]
      
      scrape_interval = "30s"
      metrics_path = "/metrics/cadvisor"
      scheme = "https"
      bearer_token_file = "/var/run/secrets/kubernetes.io/serviceaccount/token"
      tls_config {
        ca_file = "/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"
        insecure_skip_verify = true
      }
    }

    prometheus.scrape "kube_state_metrics" {
      targets = [{
        __address__ = "kube-state-metrics.kube-system.svc.cluster.local:8080",
      }]
      forward_to = [prometheus.remote_write.default.receiver]
      
      scrape_interval = "30s"
      metrics_path = "/metrics"
    }

    prometheus.remote_write "default" {
      endpoint {
        url = "http://lgtm.default.svc.cluster.local:9090/api/v1/write"
      }
      
      external_labels = {
        cluster = "kind-local",
        source = "alloy",
      }
    }

    loki.source.kubernetes "pod_logs" {
      targets    = discovery.kubernetes.pods.targets
      forward_to = [loki.process.add_labels.receiver]
    }

    loki.process "add_labels" {
      forward_to = [loki.write.default.receiver]

      // Extract JSON fields if present
      stage.json {
        expressions = {
          level     = "level",
          timestamp = "time",
          message   = "msg",
          logger    = "logger",
        }
      }

      // Set log level label if extracted
      stage.labels {
        values = {
          level = null,
        }
      }

      // Parse common log formats
      stage.regex {
        expression = "^(?P<timestamp>\\d{4}-\\d{2}-\\d{2}[T ]\\d{2}:\\d{2}:\\d{2}(?:\\.\\d+)?(?:Z|[+-]\\d{2}:\\d{2})?).* (?P<level>TRACE|DEBUG|INFO|WARN|WARNING|ERROR|FATAL|PANIC).*"
      }

      // Set parsed level as label
      stage.labels {
        values = {
          level = null,
        }
      }

      // Parse Kubernetes pod logs format
      stage.regex {
        expression = "^(?P<timestamp>\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d+Z) (?P<stream>stdout|stderr) (?P<logtag>[FP]) (?P<message>.*)"
      }

      // Add stream label
      stage.labels {
        values = {
          stream = null,
        }
      }

      // Use extracted timestamp if available
      stage.timestamp {
        source = "timestamp"
        format = "RFC3339Nano"
      }

      // Drop empty or debug messages to reduce noise (optional)
      stage.drop {
        expression = "(?i)(debug|trace)"
        drop_counter_reason = "debug_logs_dropped"
      }
    }

    loki.write "default" {
      endpoint {
        url = "http://lgtm.default.svc.cluster.local:3100/loki/api/v1/push"
      }
      
      external_labels = {
        cluster = "kind-local",
        source = "alloy",
      }
    }
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: alloy
spec:
  selector:
    matchLabels:
      app: alloy
  template:
    metadata:
      labels:
        app: alloy
    spec:
      serviceAccountName: alloy
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      containers:
      - name: alloy
        image: grafana/alloy:v1.5.0
        args:
        - run
        - /etc/alloy/config.alloy
        - --server.http.listen-addr=0.0.0.0:12345
        - --cluster.enabled=false
        - --disable-reporting=true
        - --storage.path=/tmp/alloy
        ports:
        - containerPort: 12345
          name: http-metrics
        env:
        - name: HOSTNAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 500m
            memory: 1Gi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 65534
        volumeMounts:
        - name: config
          mountPath: /etc/alloy
        - name: tmp
          mountPath: /tmp
        - name: varlog
          mountPath: /var/log
          readOnly: true
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: etcmachineid
          mountPath: /etc/machine-id
          readOnly: true
      volumes:
      - name: config
        configMap:
          name: alloy-config
      - name: tmp
        emptyDir: {}
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: etcmachineid
        hostPath:
          path: /etc/machine-id
      tolerations:
      - effect: NoSchedule
        operator: Exists
      - effect: NoExecute
        operator: Exists
---
apiVersion: v1
kind: Service
metadata:
  name: alloy
spec:
  selector:
    app: alloy
  ports:
  - name: http-metrics
    port: 12345
    targetPort: 12345
